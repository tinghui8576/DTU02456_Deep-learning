Step 500     training accuracy: 0.51503125
             test accuracy: 0.5178
Step 1000    training accuracy: 0.5245842889908257
             test accuracy: 0.5182
Step 1500    training accuracy: 0.52609375
             test accuracy: 0.5247
Step 2000    training accuracy: 0.5331135321100917
             test accuracy: 0.5287
Step 2500    training accuracy: 0.5368303571428571
             test accuracy: 0.5325
Step 3000    training accuracy: 0.53946875
             test accuracy: 0.5362
Step 3500    training accuracy: 0.5475050403225806
             test accuracy: 0.5393
Step 4000    training accuracy: 0.5493055555555556
             test accuracy: 0.5346
Step 4500    training accuracy: 0.54959375
             test accuracy: 0.5385
Step 5000    training accuracy: 0.550984172077922
             test accuracy: 0.5454
Step 5500    training accuracy: 0.5432692307692307
             test accuracy: 0.5401
Step 6000    training accuracy: 0.56034375
             test accuracy: 0.5513
Step 6500    training accuracy: 0.5697361680327869
             test accuracy: 0.5431
Step 7000    training accuracy: 0.56215625
             test accuracy: 0.5534
Step 7500    training accuracy: 0.5695008116883117
             test accuracy: 0.5542
Step 8000    training accuracy: 0.5760416666666667
             test accuracy: 0.5527
Step 8500    training accuracy: 0.5723125
             test accuracy: 0.5614
Step 9000    training accuracy: 0.5784390703517588
             test accuracy: 0.5648
Step 9500    training accuracy: 0.5750269396551724
             test accuracy: 0.5618
Step 10000   training accuracy: 0.5843125
             test accuracy: 0.5673
Step 10500   training accuracy: 0.5876684131736527
             test accuracy: 0.568
Step 11000   training accuracy: 0.5928485576923077
             test accuracy: 0.569
Step 11500   training accuracy: 0.5906875
             test accuracy: 0.5712
Step 12000   training accuracy: 0.5939236111111111
             test accuracy: 0.5747
Step 12500   training accuracy: 0.5958125
             test accuracy: 0.5743
Step 13000   training accuracy: 0.5999935963114754
             test accuracy: 0.5757
Step 13500   training accuracy: 0.5948118932038835
             test accuracy: 0.5719
Step 14000   training accuracy: 0.60203125
             test accuracy: 0.5748
Step 14500   training accuracy: 0.6081589033018868
             test accuracy: 0.5815
Step 15000   training accuracy: 0.6115757042253521
             test accuracy: 0.5835
Step 15500   training accuracy: 0.60715625
             test accuracy: 0.5842
Step 16000   training accuracy: 0.61015625
             test accuracy: 0.5859
Step 16500   training accuracy: 0.6107772435897436
             test accuracy: 0.5862
Step 17000   training accuracy: 0.61384375
             test accuracy: 0.5876
Step 17500   training accuracy: 0.6147592905405406
             test accuracy: 0.5929
Step 18000   training accuracy: 0.6261160714285714
             test accuracy: 0.5929
Step 18500   training accuracy: 0.61971875
             test accuracy: 0.5851
Step 19000   training accuracy: 0.6243265086206896
             test accuracy: 0.5903
Step 19500   training accuracy: 0.62221875
             test accuracy: 0.5948
Step 20000   training accuracy: 0.6247222222222222
             test accuracy: 0.5948
Step 20500   training accuracy: 0.6276041666666666
             test accuracy: 0.6015
Step 21000   training accuracy: 0.62590625
             test accuracy: 0.5969
Step 21500   training accuracy: 0.6303432642487047
             test accuracy: 0.5988
Step 22000   training accuracy: 0.6403245192307693
             test accuracy: 0.6017
Step 22500   training accuracy: 0.6315
             test accuracy: 0.6043
Step 23000   training accuracy: 0.6388781055900621
             test accuracy: 0.6008
Finished training.
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 15, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=375, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 15, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=375, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Output shape: torch.Size([2, 5, 14, 14])
Output logits:
[[[[1.19187284e+00 2.38080949e-01 8.55887413e-01 ... 1.37709928e+00
    8.20973158e-01 9.74980220e-02]
   [0.00000000e+00 4.38126385e-01 1.21606624e+00 ... 3.77364188e-01
    2.95074195e-01 4.11980897e-01]
   [6.31841183e-01 9.67683256e-01 3.68269056e-01 ... 1.06636493e-03
    4.89302993e-01 6.58116281e-01]
   ...
   [6.26476407e-01 0.00000000e+00 3.48938912e-01 ... 8.69100928e-01
    6.56121612e-01 9.66176093e-01]
   [8.59275699e-01 3.69962364e-01 2.19344288e-01 ... 2.99338162e-01
    1.10246444e+00 1.02251422e+00]
   [8.63440335e-01 1.09316158e+00 4.24580097e-01 ... 0.00000000e+00
    5.13924479e-01 8.98542523e-01]]

  [[7.83909023e-01 0.00000000e+00 1.52007318e+00 ... 0.00000000e+00
    7.44673491e-01 1.09932089e+00]
   [7.45571554e-01 7.14462578e-01 5.73587835e-01 ... 0.00000000e+00
    4.87651259e-01 9.60436046e-01]
   [5.87640762e-01 3.73864383e-01 6.78724289e-01 ... 8.00733566e-01
    3.49940747e-01 4.66289252e-01]
   ...
   [5.41762531e-01 2.26128012e-01 3.95900041e-01 ... 8.86082947e-01
    4.16408509e-01 7.36248314e-01]
   [3.73809874e-01 4.02505100e-01 0.00000000e+00 ... 0.00000000e+00
    2.74347782e-01 1.12228560e+00]
   [1.16299391e+00 7.71199316e-02 3.42637509e-01 ... 5.78107178e-01
    5.16063750e-01 0.00000000e+00]]

  [[4.59513396e-01 3.30617964e-01 6.63989723e-01 ... 4.94937420e-01
    7.88724840e-01 0.00000000e+00]
   [3.24017346e-01 1.22113204e+00 4.75213289e-01 ... 8.40689480e-01
    1.78391039e+00 4.13999051e-01]
   [3.15981746e-01 1.51623094e+00 2.07917705e-01 ... 1.76593766e-01
    8.58994663e-01 1.34449804e+00]
   ...
   [0.00000000e+00 9.91305411e-01 3.92035097e-01 ... 1.17967105e+00
    3.94981921e-01 3.35338444e-01]
   [8.73423994e-01 4.84865129e-01 4.07879233e-01 ... 3.77924114e-01
    1.08072472e+00 1.12530553e+00]
   [1.10244346e+00 1.08662212e+00 1.02926254e+00 ... 1.08010817e+00
    1.88468933e-01 1.35754752e+00]]

  [[8.49532843e-01 1.13220859e+00 2.91257113e-01 ... 2.63137817e-01
    5.34409523e-01 4.06541646e-01]
   [4.92661566e-01 3.25931534e-02 7.21473575e-01 ... 3.01392913e-01
    1.16433930e+00 9.95624900e-01]
   [8.36760640e-01 2.48168617e-01 1.10022020e+00 ... 8.30933392e-01
    9.02558863e-01 1.05582535e+00]
   ...
   [3.15680653e-01 7.36337304e-01 0.00000000e+00 ... 1.32869974e-01
    4.97239381e-01 8.38936985e-01]
   [6.06026530e-01 6.16994739e-01 1.31259692e+00 ... 4.44724172e-01
    8.78299415e-01 4.62699801e-01]
   [6.09615028e-01 9.87823248e-01 9.80693772e-02 ... 5.37714124e-01
    1.79473758e-01 6.32189870e-01]]

  [[5.79934657e-01 8.31846058e-01 1.06685805e+00 ... 8.41468275e-01
    1.32613599e+00 4.58858639e-01]
   [5.59534550e-01 7.67122209e-01 1.17218792e+00 ... 3.30459893e-01
    7.01431513e-01 9.65754032e-01]
   [1.15961862e+00 1.14160371e+00 7.98324227e-01 ... 0.00000000e+00
    6.02835238e-01 4.74395961e-01]
   ...
   [1.17617917e+00 3.88632536e-01 3.09703290e-01 ... 0.00000000e+00
    9.20132339e-01 5.44386208e-01]
   [3.17635894e-01 6.11600757e-01 1.23903191e+00 ... 0.00000000e+00
    1.00656152e+00 7.86312759e-01]
   [5.05918384e-01 1.18492305e+00 4.96465296e-01 ... 2.18315616e-01
    6.20086312e-01 8.57243121e-01]]]


 [[[1.38050747e+00 9.24520969e-01 7.45754361e-01 ... 3.40711594e-01
    6.65424645e-01 1.06931224e-01]
   [5.12353659e-01 9.01753008e-01 7.79738843e-01 ... 6.71292722e-01
    5.31551957e-01 8.91466439e-01]
   [2.51864642e-01 4.16853786e-01 1.08862650e+00 ... 3.83406460e-01
    4.83127862e-01 7.84543622e-03]
   ...
   [3.94716442e-01 7.95996487e-01 1.34367096e+00 ... 3.53810996e-01
    8.33641946e-01 4.71675217e-01]
   [3.00089687e-01 6.04907572e-01 5.78731179e-01 ... 3.76563996e-01
    5.62833428e-01 2.19271272e-01]
   [0.00000000e+00 1.08999586e+00 3.04588437e-01 ... 9.22038078e-01
    0.00000000e+00 6.27704203e-01]]

  [[1.35410440e+00 0.00000000e+00 1.04745400e+00 ... 4.71043408e-01
    1.42973149e+00 2.08444774e-01]
   [6.49487555e-01 0.00000000e+00 3.06517065e-01 ... 6.45384252e-01
    1.01876545e+00 7.21528590e-01]
   [6.89690113e-01 4.67316270e-01 2.00412601e-01 ... 1.02311528e+00
    1.49225760e+00 0.00000000e+00]
   ...
   [7.96522975e-01 7.69850791e-01 2.61737227e-01 ... 8.93717706e-01
    3.47239494e-01 2.28809893e-01]
   [5.33454001e-01 5.89412749e-01 6.49933636e-01 ... 9.54276800e-01
    1.91589415e-01 5.19511938e-01]
   [8.00690532e-01 0.00000000e+00 6.52682483e-01 ... 5.36254942e-01
    3.87200207e-01 9.02760029e-01]]

  [[1.02348340e+00 5.85590363e-01 1.42689741e+00 ... 5.13471544e-01
    4.92327541e-01 2.65183359e-01]
   [0.00000000e+00 7.47733355e-01 1.72201598e+00 ... 1.04884827e+00
    1.57497609e+00 4.34455633e-01]
   [7.38995492e-01 1.23006880e+00 4.98877585e-01 ... 1.13323069e+00
    8.23908329e-01 3.05946529e-01]
   ...
   [1.07570040e+00 6.47510469e-01 5.05283296e-01 ... 9.61518109e-01
    5.15765429e-01 1.00267184e+00]
   [1.89176750e+00 5.87337196e-01 1.01145113e+00 ... 1.07314467e+00
    1.08095169e+00 3.87190640e-01]
   [7.39826322e-01 6.14510119e-01 0.00000000e+00 ... 7.88825333e-01
    9.38408911e-01 1.41700876e+00]]

  [[5.50303161e-01 0.00000000e+00 1.15190613e+00 ... 3.78717184e-01
    1.42380178e-01 4.10264671e-01]
   [1.14978218e+00 2.12143824e-01 9.18178499e-01 ... 4.84842718e-01
    5.76975584e-01 2.53253907e-01]
   [6.07595801e-01 4.25963253e-01 4.49115299e-02 ... 6.94628000e-01
    4.43511486e-01 4.74649101e-01]
   ...
   [5.44779241e-01 5.96756577e-01 1.24402153e+00 ... 9.41029966e-01
    0.00000000e+00 2.98841923e-01]
   [7.22638547e-01 8.45885575e-01 5.80329299e-01 ... 3.27314436e-01
    8.09034169e-01 8.14477727e-02]
   [6.71358928e-02 8.44343364e-01 9.59256738e-02 ... 4.35540855e-01
    3.24602306e-01 8.39720547e-01]]

  [[4.62313712e-01 5.97136796e-01 1.19529939e+00 ... 3.14707369e-01
    4.54408497e-01 1.33225359e-02]
   [8.05129528e-01 8.15133810e-01 5.75771332e-01 ... 1.04028332e+00
    3.44642520e-01 4.68858719e-01]
   [7.10167229e-01 9.03495371e-01 3.79920989e-01 ... 7.37409532e-01
    1.54490948e-01 7.10126460e-01]
   ...
   [8.83609653e-01 8.87789965e-01 9.93602097e-01 ... 4.57851887e-01
    6.15138769e-01 4.61266160e-01]
   [6.50304556e-01 9.32755172e-01 1.27219111e-01 ... 5.93343377e-01
    1.20403278e+00 6.75821722e-01]
   [4.22917068e-01 8.24613273e-01 2.36568779e-01 ... 4.55320835e-01
    5.28802872e-01 4.29837495e-01]]]]
Output probabilities:
[[[[0.29427502 0.14003469 0.17947696 ... 0.3876341  0.1885761
    0.1346303 ]
   [0.12695444 0.1523804  0.2801447  ... 0.19394737 0.09495955
    0.13764697]
   [0.17830044 0.20161691 0.14636219 ... 0.12972486 0.16809092
    0.16306446]
   ...
   [0.20329961 0.11748505 0.21012467 ... 0.23366813 0.21221215
    0.2588573 ]
   [0.2507694  0.17518054 0.11406648 ... 0.21182583 0.24253586
    0.21862154]
   [0.19629113 0.22979893 0.1802463  ... 0.11515792 0.21968015
    0.21207236]]

  [[0.19569375 0.11036678 0.3487072  ... 0.09780372 0.17472301
    0.3666308 ]
   [0.267575   0.20088172 0.14735253 ... 0.13298318 0.11512609
    0.23820876]
   [0.17059112 0.11133577 0.19964474 ... 0.2886119  0.14622445
    0.13460152]
   ...
   [0.18678662 0.14729525 0.22022773 ... 0.23767018 0.16697988
    0.20568569]
   [0.15432611 0.18097517 0.09160054 ... 0.15702833 0.10595695
    0.24155892]
   [0.26484707 0.08319299 0.1660654  ... 0.20528752 0.22015059
    0.08634795]]

  [[0.14147957 0.15361159 0.14813872 ... 0.16043678 0.18259184
    0.1221237 ]
   [0.17553626 0.33341426 0.13354698 ... 0.3082503  0.42085448
    0.13792506]
   [0.13000989 0.34894598 0.12467781 ... 0.15461577 0.24327603
    0.32392997]
   ...
   [0.1086579  0.3165928  0.2193782  ... 0.3187707  0.16344012
    0.13774985]
   [0.2543426  0.19651128 0.13773291 ... 0.22914393 0.2373201
    0.24228953]
   [0.24928631 0.22830108 0.32997164 ... 0.33913985 0.15865262
    0.3356042 ]]

  [[0.20896666 0.34241307 0.10204528 ... 0.12724322 0.14159034
    0.18338285]
   [0.20778209 0.10158002 0.17083763 ... 0.17975873 0.22649346
    0.24674028]
   [0.21885064 0.09818513 0.3043065  ... 0.29746088 0.2541084
    0.24270695]
   ...
   [0.14899087 0.24534082 0.14822955 ... 0.11190731 0.1810375
    0.22792985]
   [0.1946659  0.22426972 0.34037027 ... 0.24497359 0.1938306
    0.12490177]
   [0.15228802 0.20682363 0.13003628 ... 0.19716059 0.15723191
    0.16248323]]

  [[0.15958498 0.2535739  0.22163181 ... 0.22688217 0.31251875
    0.19323228]
   [0.22215222 0.21174356 0.2681182  ... 0.18506046 0.14256646
    0.23947893]
   [0.30224788 0.23991624 0.22500879 ... 0.12958659 0.18830016
    0.13569713]
   ...
   [0.35226497 0.17328604 0.20203994 ... 0.09798369 0.27633038
    0.16977723]
   [0.145896   0.22306328 0.31622976 ... 0.15702833 0.2203565
    0.17262828]
   [0.13728747 0.2518834  0.1936804  ... 0.1432541  0.2442847
    0.20349228]]]


 [[[0.28498974 0.30990633 0.13519143 ... 0.18723595 0.18549311
    0.18039759]
   [0.1672851  0.27159807 0.16252819 ... 0.17515244 0.13618995
    0.27318954]
   [0.1391675  0.14403206 0.35583627 ... 0.12816556 0.14640602
    0.14382856]
   ...
   [0.13768868 0.21045111 0.2957582  ... 0.1340359  0.27927408
    0.18811397]
   [0.09881381 0.17769317 0.19034903 ... 0.14320798 0.15274978
    0.16714312]
   [0.12628657 0.2851515  0.204094   ... 0.26336372 0.1233176
    0.15208858]]

  [[0.27756363 0.12294649 0.18279974 ... 0.21330036 0.39834747
    0.19967215]
   [0.19187295 0.11023013 0.10125374 ... 0.17067279 0.22168647
    0.23049472]
   [0.21561702 0.15148678 0.14638744 ... 0.24299276 0.4016229
    0.14270456]
   ...
   [0.20577879 0.20502004 0.10024413 ... 0.22998509 0.17170729
    0.1475523 ]
   [0.12478618 0.17496108 0.20439653 ... 0.2551906  0.10537835
    0.22567393]
   [0.28125006 0.09587304 0.28907168 ... 0.17906572 0.1816285
    0.20024045]]

  [[0.1994232  0.22081815 0.2671565  ... 0.22254503 0.15601009
    0.21132883]
   [0.10021781 0.23282886 0.41701767 ... 0.2554974  0.38663256
    0.17297637]
   [0.22651453 0.32481343 0.19729929 ... 0.2712788  0.20585342
    0.1937799 ]
   ...
   [0.27204818 0.1814114  0.12788795 ... 0.24611892 0.20322569
    0.31991157]
   [0.4853718  0.17459829 0.29341245 ... 0.28740105 0.25644633
    0.19770376]
   [0.26464254 0.17724535 0.15050438 ... 0.2305167  0.31518885
    0.33487844]]

  [[0.12424419 0.12294649 0.20292643 ... 0.19448891 0.10994423
    0.24432436]
   [0.31643823 0.13628036 0.18666044 ... 0.14535901 0.14251885
    0.14430849]
   [0.19862318 0.14535011 0.12530562 ... 0.17495774 0.14071934
    0.22939046]
   ...
   [0.15998146 0.17243382 0.2677069  ... 0.2411277  0.12133456
    0.15825613]
   [0.15077464 0.22611332 0.19065346 ... 0.13632591 0.19539084
    0.14562386]
   [0.135056   0.22304381 0.16565675 ... 0.16190971 0.17060746
    0.18800704]]

  [[0.11377917 0.22338259 0.2119259  ... 0.18242976 0.15020509
    0.16427709]
   [0.22418585 0.24906255 0.13253993 ... 0.25331843 0.11297213
    0.17903085]
   [0.22007774 0.23431762 0.17517143 ... 0.1826051  0.10539834
    0.29029655]
   ...
   [0.22450285 0.23068355 0.2084029  ... 0.14873238 0.22445843
    0.18616603]
   [0.1402536  0.24663411 0.12118851 ... 0.17787434 0.29003468
    0.2638553 ]
   [0.19276479 0.21868625 0.1906732  ... 0.16514416 0.2092576
    0.12478551]]]]
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 15, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=375, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 15, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=375, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Output shape: torch.Size([2, 10, 5, 5])
Output logits:
[[[[0.00000000e+00 6.92823678e-02 0.00000000e+00 1.22492015e-02
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [1.60075769e-01 3.21982726e-02 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.95733711e-01
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 5.54253608e-02
    0.00000000e+00]]

  [[0.00000000e+00 9.30991918e-02 4.18950282e-02 0.00000000e+00
    9.44987983e-02]
   [0.00000000e+00 1.19376726e-01 1.01747818e-01 0.00000000e+00
    2.39683613e-02]
   [2.82256696e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00
    1.69281557e-01]
   [0.00000000e+00 2.46496480e-02 0.00000000e+00 0.00000000e+00
    8.39539021e-02]
   [1.13570057e-02 0.00000000e+00 0.00000000e+00 2.50054926e-01
    0.00000000e+00]]

  [[7.13565946e-01 5.17459631e-01 6.26210570e-01 6.15028799e-01
    1.00549066e+00]
   [7.19905853e-01 8.70225489e-01 4.77855653e-01 6.05221570e-01
    6.51188374e-01]
   [9.04026985e-01 5.87704659e-01 5.24794579e-01 5.19729376e-01
    4.50681388e-01]
   [7.86029994e-01 6.47414327e-01 7.27460682e-01 4.56287235e-01
    5.76619208e-01]
   [7.50826180e-01 4.67018306e-01 7.38523304e-01 3.91536742e-01
    7.67244041e-01]]

  [[3.45598549e-01 5.26933670e-01 3.42798859e-01 4.08281952e-01
    1.52106240e-01]
   [5.11486769e-01 1.23732686e-01 3.93687069e-01 3.01493496e-01
    3.52530062e-01]
   [3.43247384e-01 3.38650644e-01 3.62447798e-01 2.34215230e-01
    4.70149279e-01]
   [2.02080786e-01 3.78743738e-01 3.52302462e-01 1.08537406e-01
    1.69886366e-01]
   [3.48278940e-01 2.52213806e-01 2.10816771e-01 3.42224628e-01
    3.56651425e-01]]

  [[3.58068943e-01 3.58118534e-01 3.55831414e-01 2.33844802e-01
    3.16143274e-01]
   [4.42989320e-01 3.52256954e-01 2.11941287e-01 3.93901855e-01
    5.04366696e-01]
   [5.01558959e-01 4.22005743e-01 2.37197921e-01 2.62987494e-01
    2.60590494e-01]
   [4.03663367e-01 2.42451817e-01 4.92506146e-01 2.11746261e-01
    4.98207211e-01]
   [4.11399424e-01 3.09421122e-01 4.63926792e-01 4.47900355e-01
    4.25291598e-01]]

  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]]

  [[3.50352168e-01 1.93563834e-01 0.00000000e+00 6.87456205e-02
    5.61519042e-02]
   [2.17553779e-01 1.85343549e-01 2.03610241e-01 3.23554635e-01
    1.40748113e-01]
   [2.29510695e-01 1.33772284e-01 0.00000000e+00 3.30786347e-01
    2.26486444e-01]
   [1.56825647e-01 2.28288099e-01 1.41362160e-01 2.97849536e-01
    3.34830105e-01]
   [7.44803399e-02 0.00000000e+00 1.77057773e-01 2.09862113e-01
    1.51829720e-01]]

  [[8.42700064e-01 7.72148550e-01 8.15983772e-01 5.97419322e-01
    8.43186498e-01]
   [7.97825158e-01 7.64412940e-01 9.40515697e-01 1.14572954e+00
    9.40913379e-01]
   [1.08885062e+00 8.84060383e-01 9.80785668e-01 7.31001794e-01
    8.42914462e-01]
   [7.41877615e-01 1.12526834e+00 8.97235930e-01 7.74495840e-01
    7.26618230e-01]
   [6.38998330e-01 6.46562338e-01 7.27499306e-01 8.38339090e-01
    9.51583147e-01]]

  [[0.00000000e+00 1.38283268e-01 0.00000000e+00 4.02577817e-02
    5.79297058e-02]
   [3.94704938e-01 0.00000000e+00 2.74367146e-02 2.02830747e-01
    0.00000000e+00]
   [0.00000000e+00 1.08019158e-01 0.00000000e+00 5.00132367e-02
    0.00000000e+00]
   [1.34633422e-01 0.00000000e+00 0.00000000e+00 4.72254977e-02
    1.04946576e-01]
   [1.29162967e-01 0.00000000e+00 0.00000000e+00 5.11363149e-04
    5.06302118e-02]]

  [[6.70191348e-02 6.65582642e-02 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 6.75083250e-02 5.12249619e-02 0.00000000e+00
    0.00000000e+00]
   [1.26101688e-01 0.00000000e+00 0.00000000e+00 1.84617609e-01
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 1.23605551e-02 0.00000000e+00
    2.06399709e-02]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.16708004e-02
    0.00000000e+00]]]


 [[[2.06932634e-01 0.00000000e+00 1.38385976e-02 2.16774285e-01
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.40233973e-01
    1.94888599e-02]
   [0.00000000e+00 1.73110425e-01 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 6.64790124e-02 0.00000000e+00 0.00000000e+00
    2.11497620e-01]]

  [[2.26190567e-01 1.36763364e-01 4.78502661e-02 0.00000000e+00
    0.00000000e+00]
   [1.03367545e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00
    1.25331640e-01]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    7.50279874e-02]
   [4.86233123e-02 0.00000000e+00 0.00000000e+00 5.89366518e-02
    2.18983263e-01]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]]

  [[4.88681823e-01 5.51241755e-01 5.10352731e-01 4.32939589e-01
    6.76327109e-01]
   [6.37901485e-01 6.21777534e-01 6.00823402e-01 4.88976538e-01
    6.88532770e-01]
   [4.61470544e-01 6.51162207e-01 5.97739577e-01 7.71389961e-01
    5.39710879e-01]
   [5.49561083e-01 3.97140980e-01 4.77090031e-01 7.00396657e-01
    5.82847536e-01]
   [4.54509288e-01 3.96038115e-01 7.69319952e-01 6.98591828e-01
    7.37563729e-01]]

  [[0.00000000e+00 4.63767439e-01 4.27820086e-01 4.31072980e-01
    1.85353532e-01]
   [2.58366615e-01 6.51969969e-01 2.33557358e-01 7.60317147e-02
    2.96910405e-01]
   [1.38403282e-01 6.83914244e-01 1.84018493e-01 4.63839859e-01
    4.33674663e-01]
   [2.42292702e-01 2.49312267e-01 4.33427781e-01 3.34100753e-01
    5.50500095e-01]
   [3.20564210e-01 1.66396454e-01 2.81511754e-01 3.91646713e-01
    3.11813354e-01]]

  [[3.87634039e-01 2.50620753e-01 4.86124724e-01 5.95038474e-01
    4.85097587e-01]
   [5.34419179e-01 4.65169400e-01 1.10730097e-01 4.09891605e-01
    4.22037005e-01]
   [3.97325546e-01 5.43132961e-01 2.01272964e-01 4.64059860e-01
    7.58217096e-01]
   [4.60910201e-01 3.05029720e-01 5.73369086e-01 2.30632365e-01
    5.68550408e-01]
   [4.28275704e-01 5.68683743e-01 2.90262610e-01 5.50277293e-01
    4.07875955e-01]]

  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
    0.00000000e+00]]

  [[2.36074388e-01 1.81419462e-01 0.00000000e+00 9.67499912e-02
    1.91681266e-01]
   [2.98996419e-01 2.82486349e-01 2.36014500e-01 1.50222465e-01
    2.52758145e-01]
   [1.18194949e-02 1.08502895e-01 9.87629872e-04 1.99322060e-01
    1.95844203e-01]
   [0.00000000e+00 2.12371618e-01 5.05830824e-01 3.87874007e-01
    2.46044785e-01]
   [3.28240663e-01 2.16604233e-01 2.93687999e-01 2.24486500e-01
    1.13727465e-01]]

  [[8.20899427e-01 9.57828164e-01 8.83454263e-01 8.54132533e-01
    7.56423891e-01]
   [7.26108193e-01 1.00296474e+00 9.39195454e-01 8.75074565e-01
    8.50538790e-01]
   [8.36071908e-01 7.32227027e-01 1.23248172e+00 6.88079000e-01
    7.17712879e-01]
   [6.15385652e-01 7.63748288e-01 9.96701777e-01 1.05507731e+00
    1.15889108e+00]
   [1.06419861e+00 7.10656047e-01 6.09720230e-01 6.09053671e-01
    8.13628614e-01]]

  [[7.19349412e-03 1.34689316e-01 1.17578641e-01 1.36624888e-01
    5.48437357e-01]
   [1.30602764e-02 3.98140639e-01 7.63898194e-02 2.02830091e-01
    0.00000000e+00]
   [0.00000000e+00 0.00000000e+00 2.56152414e-02 1.17181815e-01
    4.69338261e-02]
   [5.81617057e-02 9.84327942e-02 6.15086183e-02 1.31870165e-01
    0.00000000e+00]
   [0.00000000e+00 1.70742199e-02 0.00000000e+00 8.41377378e-02
    0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00 1.75706614e-02 2.58008987e-02
    1.39947250e-01]
   [6.31007478e-02 0.00000000e+00 0.00000000e+00 1.75373957e-01
    3.53228184e-03]
   [0.00000000e+00 2.56657768e-02 2.13957533e-01 7.66832009e-02
    8.79773498e-02]
   [0.00000000e+00 1.42299533e-01 3.46350461e-01 0.00000000e+00
    1.32789701e-01]
   [0.00000000e+00 2.15152323e-01 6.75491691e-02 2.13332903e-02
    0.00000000e+00]]]]
Output probabilities:
[[[[0.07301312 0.0789987  0.07685837 0.08060306 0.07241326]
   [0.07028864 0.07413209 0.07515561 0.06935813 0.07281131]
   [0.07774344 0.07684772 0.07656267 0.07710359 0.07559106]
   [0.07502047 0.07138849 0.07275023 0.09569091 0.07521165]
   [0.07595605 0.08227944 0.07586429 0.07879589 0.0718489 ]]

  [[0.07301312 0.08090279 0.08014676 0.07962177 0.07958999]
   [0.07028864 0.08353162 0.08320509 0.06935813 0.07457756]
   [0.06813998 0.07441277 0.07656267 0.07710359 0.0895341 ]
   [0.07502047 0.07317007 0.07275023 0.07868004 0.0817986 ]
   [0.0768236  0.08227944 0.07586429 0.09572604 0.0718489 ]]

  [[0.14903855 0.123669   0.14376427 0.14727716 0.19792339]
   [0.14438973 0.17698659 0.12119688 0.12704037 0.13963887]
   [0.16359036 0.133932   0.12939946 0.12965527 0.11863118]
   [0.1646449  0.13639446 0.15057974 0.12417313 0.13387753]
   [0.16093186 0.13125469 0.15877202 0.11027443 0.15474975]]

  [[0.1031555  0.12484621 0.10828464 0.11976954 0.08430959]
   [0.11722522 0.08389627 0.11141342 0.09376361 0.10358591]
   [0.09337147 0.10440507 0.11000849 0.0974525  0.12096331]
   [0.09182107 0.10425925 0.10347547 0.08770045 0.0891386 ]
   [0.10760141 0.10588304 0.09366858 0.10496847 0.10263886]]

  [[0.10444995 0.10545323 0.10970509 0.10059799 0.09933846]
   [0.10946443 0.10543614 0.09289799 0.10284112 0.12057089]
   [0.10938758 0.11348076 0.09705789 0.10029715 0.09809422]
   [0.11232814 0.09097534 0.11904936 0.09723549 0.12378094]
   [0.11461221 0.11211694 0.12064747 0.11666841 0.10993143]]

  [[0.07301312 0.07371078 0.07685837 0.07962177 0.07241326]
   [0.07028864 0.07413209 0.07515561 0.06935813 0.07281131]
   [0.06624357 0.07441277 0.07656267 0.07710359 0.07559106]
   [0.07502047 0.07138849 0.07275023 0.07868004 0.07521165]
   [0.07595605 0.08227944 0.07586429 0.07454742 0.0718489 ]]

  [[0.10364704 0.08945296 0.07685837 0.08528794 0.07659574]
   [0.08737106 0.08922774 0.09212727 0.09585513 0.08381561]
   [0.08333337 0.08506365 0.07656267 0.107333   0.09480523]
   [0.08775832 0.08969589 0.08379675 0.10597879 0.10512355]
   [0.08182929 0.08227944 0.09055921 0.09195483 0.08362938]]

  [[0.16958243 0.15954046 0.17380746 0.1447064  0.16827103]
   [0.15609041 0.15921594 0.19249621 0.21811292 0.18656592]
   [0.1968002  0.18013164 0.20415823 0.16015652 0.1756077 ]
   [0.15753357 0.21995106 0.17844278 0.1706962  0.15554334]
   [0.14390498 0.15706876 0.15703133 0.1723926  0.18607473]]

  [[0.07301312 0.08464213 0.07685837 0.08289255 0.07673202]
   [0.10430457 0.07413209 0.07724618 0.08495436 0.07281131]
   [0.06624357 0.08290096 0.07656267 0.08105785 0.07559106]
   [0.08583222 0.07138849 0.07275023 0.08248488 0.08353391]
   [0.08642853 0.08227944 0.07586429 0.07458555 0.07558028]]

  [[0.07807409 0.07878379 0.07685837 0.07962177 0.07241326]
   [0.07028864 0.07930941 0.07910576 0.06935813 0.07281131]
   [0.07514654 0.07441277 0.07656267 0.09273698 0.07559106]
   [0.07502047 0.07138849 0.07365505 0.07868004 0.07678015]
   [0.07595605 0.08227944 0.07586429 0.08008641 0.0718489 ]]]


 [[[0.09364669 0.07296091 0.07538281 0.09027078 0.07134038]
   [0.07409339 0.0670436  0.07629338 0.07579201 0.07338321]
   [0.079733   0.07224863 0.07174509 0.09063383 0.07337632]
   [0.07966695 0.09177445 0.06769023 0.07033169 0.06603654]
   [0.07259554 0.08198301 0.07650306 0.07449467 0.09103225]]

  [[0.09546762 0.08365383 0.07799081 0.07267806 0.07134038]
   [0.08216209 0.0670436  0.07629338 0.07579201 0.08318166]
   [0.079733   0.07224863 0.07174509 0.07127842 0.07756687]
   [0.08363634 0.07718642 0.06769023 0.0746014  0.08220297]
   [0.07259554 0.07671008 0.07650306 0.07449467 0.07367889]]

  [[0.12412366 0.12661685 0.12385276 0.1120538  0.14030094]
   [0.14022215 0.12485096 0.13913012 0.12358999 0.14609076]
   [0.12648883 0.13855615 0.1304329  0.15415885 0.12344839]
   [0.1380224  0.11481986 0.10907459 0.14168683 0.11828012]
   [0.11436701 0.11398549 0.16511641 0.14980276 0.15405042]]

  [[0.07614174 0.11601173 0.11404131 0.11184484 0.08586841]
   [0.09593713 0.128678   0.09636504 0.08177935 0.09875141]
   [0.09156845 0.14316927 0.08624033 0.11334468 0.11102851]
   [0.10150901 0.09904119 0.10441461 0.09823114 0.11451527]
   [0.10002975 0.09059776 0.10137663 0.11020853 0.10063797]]

  [[0.11219411 0.09374184 0.12088811 0.13177264 0.11588058]
   [0.12643719 0.10675244 0.08522683 0.11419237 0.11191417]
   [0.11862995 0.12436818 0.08774127 0.11336962 0.15359657]
   [0.12631325 0.10471614 0.12009834 0.08857546 0.11660108]
   [0.11140577 0.13546547 0.10226765 0.12915394 0.11078509]]

  [[0.07614174 0.07296091 0.07434681 0.07267806 0.07134038]
   [0.07409339 0.0670436  0.07629338 0.07579201 0.07338321]
   [0.079733   0.07224863 0.07174509 0.07127842 0.07196014]
   [0.07966695 0.07718642 0.06769023 0.07033169 0.06603654]
   [0.07259554 0.07671008 0.07650306 0.07449467 0.07367889]]

  [[0.09641588 0.08747415 0.07434681 0.08006106 0.0864135 ]
   [0.0999153  0.08892822 0.09660212 0.08807735 0.09448616]
   [0.08068099 0.08052892 0.07181598 0.08700065 0.0875278 ]
   [0.07966695 0.09544929 0.11225496 0.10365795 0.08445788]
   [0.10080057 0.09526259 0.10261857 0.09324349 0.08255326]]

  [[0.17303535 0.19013837 0.17986292 0.17074515 0.1520009 ]
   [0.15315257 0.1827845  0.19515257 0.18182915 0.17178334]
   [0.18396682 0.150256   0.24606633 0.14183615 0.14749956]
   [0.14741334 0.16566569 0.18339525 0.20200649 0.21041867]
   [0.21041927 0.15613002 0.14075926 0.13697265 0.16622542]]

  [[0.07669143 0.08348051 0.08362307 0.08331799 0.12345786]
   [0.07506742 0.09983151 0.0823498  0.09283493 0.07338321]
   [0.079733   0.07224863 0.0736066  0.08014002 0.07541802]
   [0.08443792 0.0851706  0.07198448 0.08024566 0.06603654]
   [0.07259554 0.07803109 0.07650306 0.08103372 0.07367889]]

  [[0.07614174 0.07296091 0.07566468 0.07457762 0.08205664]
   [0.0789194  0.0670436  0.07629338 0.09032072 0.07364289]
   [0.079733   0.07412695 0.08886132 0.0769593  0.07857783]
   [0.07966695 0.08898991 0.0957071  0.07033169 0.07541437]
   [0.07259554 0.09512439 0.08184932 0.07610096 0.07367889]]]]
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(5, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(10, 25, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(20, 25, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Output shape: torch.Size([2, 50, 2, 2])
Output logits:
[[[[1.81023821e-01 2.31262267e-01]
   [2.34640822e-01 1.95023239e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.81668752e-01 2.11086586e-01]
   [2.59596795e-01 2.36804232e-01]]

  [[5.75834289e-02 3.19606811e-02]
   [5.77406883e-02 7.60040432e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 7.24657178e-02]
   [5.79823628e-02 8.90593976e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[7.15906546e-02 2.00637385e-01]
   [1.15700021e-01 1.61290422e-01]]

  [[2.69027710e-01 3.03317398e-01]
   [4.09905136e-01 4.19302523e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[4.74214077e-01 4.13058519e-01]
   [4.91446465e-01 5.04042864e-01]]

  [[3.19953799e-01 4.12672132e-01]
   [4.62370187e-01 3.64941925e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [3.29357870e-02 1.79910916e-03]]

  [[4.06466089e-02 0.00000000e+00]
   [4.29423042e-02 1.06208488e-01]]

  [[2.39426032e-01 1.25013322e-01]
   [9.83014703e-02 9.53671262e-02]]

  [[3.93840224e-01 3.99006695e-01]
   [4.00820315e-01 3.73587817e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.32484698e-01 2.20026553e-01]
   [2.29607105e-01 1.76940605e-01]]

  [[4.43265200e-01 4.58933413e-01]
   [4.71912950e-01 4.06934321e-01]]

  [[5.47299206e-01 4.98021454e-01]
   [5.11709690e-01 4.88183498e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[4.33298528e-01 3.21338594e-01]
   [3.74851942e-01 4.04535383e-01]]

  [[2.99371742e-02 2.10102439e-01]
   [5.65858595e-02 1.20185189e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.27496386e-01 2.47945786e-01]
   [2.27288887e-01 1.86872616e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [3.48450430e-02 0.00000000e+00]]

  [[2.31866524e-01 3.38096529e-01]
   [2.43195966e-01 3.31482708e-01]]

  [[5.01238406e-01 3.86705458e-01]
   [4.32272881e-01 3.61328363e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[3.56670290e-01 4.05028701e-01]
   [2.47622028e-01 3.43058348e-01]]

  [[4.33588117e-01 4.30361331e-01]
   [4.09992188e-01 4.78772312e-01]]

  [[1.83335721e-01 1.81560040e-01]
   [2.22735226e-01 1.35218486e-01]]

  [[0.00000000e+00 1.80009604e-02]
   [7.97996745e-02 2.62458455e-02]]

  [[1.72014520e-01 2.12904111e-01]
   [1.25292197e-01 1.98980659e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 4.79490682e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[1.72690108e-01 5.23998141e-02]
   [5.59667982e-02 8.64524320e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [1.76593307e-02 0.00000000e+00]]

  [[4.34300780e-01 3.29757929e-01]
   [3.64201128e-01 3.55265081e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.06005678e-01 1.15709491e-01]
   [1.46660477e-01 1.49270415e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]]


 [[[2.46878743e-01 1.97339445e-01]
   [1.69563442e-01 1.52579248e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.52696633e-01 2.46470869e-01]
   [2.73787290e-01 1.61106274e-01]]

  [[4.86680269e-02 5.87275662e-02]
   [6.29390255e-02 1.36054710e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[1.07940257e-01 8.66536051e-02]
   [4.70853671e-02 2.21734047e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[3.50685902e-02 1.11460470e-01]
   [9.99644101e-02 1.43845290e-01]]

  [[3.35759938e-01 3.39588344e-01]
   [3.14268142e-01 3.17154497e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[5.05523324e-01 5.65665722e-01]
   [4.66799915e-01 4.94214892e-01]]

  [[4.26353723e-01 4.93446976e-01]
   [3.91386390e-01 3.88644964e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 1.31637964e-04]
   [1.20509323e-02 1.67011153e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 1.17249126e-02]]

  [[1.37124002e-01 1.57640815e-01]
   [1.03632241e-01 6.23846948e-02]]

  [[3.23062956e-01 4.01713371e-01]
   [3.91613215e-01 3.72606397e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[1.58997595e-01 1.68903127e-01]
   [1.94636554e-01 3.00658554e-01]]

  [[4.51172501e-01 4.72057074e-01]
   [5.65165281e-01 4.74665970e-01]]

  [[5.62560976e-01 5.82041025e-01]
   [5.09048343e-01 5.06840348e-01]]

  [[1.63512025e-02 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[3.33718181e-01 3.22053522e-01]
   [4.20115292e-01 3.46967548e-01]]

  [[6.45240024e-02 1.49416193e-01]
   [1.07832730e-01 2.91353967e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[7.35622048e-02 1.71538800e-01]
   [1.92845553e-01 1.39901832e-01]]

  [[0.00000000e+00 5.05509647e-03]
   [2.33926456e-02 6.57169372e-02]]

  [[2.17991099e-01 3.85474980e-01]
   [4.06039894e-01 3.47795427e-01]]

  [[4.21751648e-01 3.24455321e-01]
   [4.27511573e-01 4.05806750e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.45083869e-01 4.19773668e-01]
   [2.64082134e-01 3.42999727e-01]]

  [[4.92702454e-01 4.19280529e-01]
   [3.48208278e-01 3.74317318e-01]]

  [[1.44629478e-01 2.38377348e-01]
   [2.11512163e-01 2.72043139e-01]]

  [[2.03753896e-02 0.00000000e+00]
   [4.22561690e-02 1.11109130e-02]]

  [[1.19842216e-01 2.44149923e-01]
   [1.89415812e-01 1.48620188e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 2.67079603e-02]]

  [[0.00000000e+00 2.56109741e-02]
   [0.00000000e+00 0.00000000e+00]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[1.70719385e-01 1.01023845e-01]
   [1.44909889e-01 1.79907590e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[3.39876145e-01 3.43500078e-01]
   [3.34661722e-01 3.05208027e-01]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[2.59441473e-02 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]

  [[1.84480488e-01 2.46453777e-01]
   [1.18044227e-01 8.49443674e-02]]

  [[0.00000000e+00 0.00000000e+00]
   [0.00000000e+00 0.00000000e+00]]]]
Output probabilities:
[[[[0.02053753 0.02168014]
   [0.02169579 0.02086768]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02271213 0.02124711]
   [0.02224405 0.02175802]]

  [[0.0181526  0.0177626 ]
   [0.01817811 0.01852613]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01849684]
   [0.01818251 0.01876958]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01840865 0.02102625]
   [0.01926284 0.02017549]]

  [[0.02242683 0.02329996]
   [0.02585186 0.02611424]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02753462 0.0260025 ]
   [0.02804819 0.02842363]]

  [[0.02359852 0.02599246]
   [0.02724439 0.02473255]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01773275 0.01720116]]

  [[0.01784774 0.01720387]
   [0.01791109 0.01909424]]

  [[0.02177269 0.0194948 ]
   [0.01893059 0.01888835]]

  [[0.02540816 0.02563968]
   [0.02561807 0.02494731]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02162208 0.02143791]
   [0.02158686 0.02049372]]

  [[0.02669551 0.02722315]
   [0.02750563 0.02579324]]

  [[0.02962236 0.02830832]
   [0.02862233 0.02797641]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02643077 0.02372366]
   [0.02496137 0.02573144]]

  [[0.01765762 0.02122621]
   [0.01815713 0.01936299]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02151449 0.02204487]
   [0.02153687 0.02069828]]

  [[0.01713683 0.01720387]
   [0.01776664 0.01717025]]

  [[0.02160872 0.02412457]
   [0.0218822  0.02391871]]

  [[0.02828887 0.02532621]
   [0.02643663 0.02464333]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02448108 0.02579454]
   [0.02197927 0.02419719]]

  [[0.02643842 0.02645633]
   [0.02585412 0.02771435]]

  [[0.02058507 0.02062893]
   [0.02143902 0.01965627]]

  [[0.01713683 0.01751636]
   [0.01858356 0.01762686]]

  [[0.02035333 0.02128576]
   [0.0194485  0.02095042]]

  [[0.01713683 0.01720387]
   [0.01715823 0.0180136 ]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02036709 0.01812938]
   [0.0181459  0.01872071]]

  [[0.01713683 0.01720387]
   [0.01746392 0.01717025]]

  [[0.02645727 0.02392424]
   [0.02469693 0.02449437]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]

  [[0.02105706 0.01931426]
   [0.01986855 0.01993443]]

  [[0.01713683 0.01720387]
   [0.01715823 0.01717025]]]


 [[[0.02216754 0.02071399]
   [0.02036012 0.02011508]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02229689 0.02175711]
   [0.02259666 0.02028733]]

  [[0.01818175 0.01803289]
   [0.01830097 0.01978542]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.019292   0.01854357]
   [0.01801312 0.01765579]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01793616 0.01900934]
   [0.01899127 0.01994016]]

  [[0.02422803 0.0238804 ]
   [0.02353016 0.02371351]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02871081 0.02993821]
   [0.02740745 0.0283069 ]]

  [[0.02652544 0.02785234]
   [0.02541657 0.02547087]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.0170066 ]
   [0.01739297 0.01755944]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01747228]]

  [[0.01986331 0.01990778]
   [0.01906105 0.01838022]]

  [[0.02392235 0.02541103]
   [0.02542233 0.02506561]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02030258 0.02013326]
   [0.02087707 0.02332554]]

  [[0.027192   0.0272629 ]
   [0.03024044 0.0277589 ]]

  [[0.03039601 0.03043249]
   [0.02859017 0.02866655]]

  [[0.01760357 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02417861 0.02346531]
   [0.02615735 0.02443113]]

  [[0.01847234 0.01974472]
   [0.01914128 0.01777914]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01864005 0.02018639]
   [0.02083971 0.01986168]]

  [[0.01731807 0.01709054]
   [0.01759135 0.01844157]]

  [[0.02153634 0.02500173]
   [0.02579175 0.02445136]]

  [[0.02640364 0.02352174]
   [0.02635153 0.02591177]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02212779 0.02587413]
   [0.02237842 0.02433438]]

  [[0.02834506 0.02586137]
   [0.02434248 0.02510853]]

  [[0.02001296 0.02158173]
   [0.02123237 0.02266753]]

  [[0.01767455 0.01700436]
   [0.01792634 0.01746155]]

  [[0.01952299 0.02170667]
   [0.02076836 0.0200356 ]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01773603]]

  [[0.01731807 0.01744548]
   [0.01718462 0.01726861]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02054196 0.01881198]
   [0.01986431 0.02067237]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.02432797 0.023974  ]
   [0.02401495 0.0234319 ]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]

  [[0.01777325 0.01700436]
   [0.01718462 0.01726861]]

  [[0.0208266  0.02175674]
   [0.01933775 0.01879959]]

  [[0.01731807 0.01700436]
   [0.01718462 0.01726861]]]]
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 15, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(15, 20, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1250, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1250, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=450, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=450, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 50, 2, 2])
torch.Size([2, 200])
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=450, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 720])
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=450, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 20, 6, 6])
torch.Size([2, 720])
Model(
  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=180, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 20, 6, 6])
torch.Size([2, 720])
Model(
  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=500, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 20, 5, 5])
torch.Size([2, 500])
Output shape: torch.Size([2, 10])
Output logits:
[[-0.0646782  -0.09156115 -0.16443731 -0.02934013  0.10419631 -0.08688261
   0.03183326  0.03032244  0.07532004  0.02395454]
 [-0.06624967 -0.09348857 -0.16111149 -0.02913158  0.1008193  -0.09225067
   0.02890203  0.03425191  0.07411348  0.02612059]]
Output probabilities:
[[0.09505301 0.09253175 0.08602824 0.09847206 0.11254006 0.09296567
  0.10468399 0.10452595 0.10933679 0.10386245]
 [0.09497012 0.09241816 0.08637519 0.09856147 0.11223909 0.09253263
  0.10445058 0.10501088 0.10928132 0.10416047]]
Model(
  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 25, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=625, out_features=200, bias=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (fc4): Linear(in_features=50, out_features=10, bias=True)
)
torch.Size([2, 25, 5, 5])
torch.Size([2, 625])
Output shape: torch.Size([2, 10])
Output logits:
[[ 0.02671859 -0.08727774  0.05349872 -0.10800657  0.01589762  0.12566578
  -0.104734   -0.03489956  0.0265766  -0.03105257]
 [ 0.01825964 -0.09282339  0.05305513 -0.1032916   0.00711751  0.12234629
  -0.1040112  -0.04009926  0.03370578 -0.03691213]]
Output probabilities:
[[0.10365497 0.09248731 0.10646836 0.09058989 0.10253937 0.11443591
  0.09088684 0.09746073 0.10364025 0.09783639]
 [0.10304452 0.09221087 0.10669311 0.09125063 0.10190275 0.11434815
  0.09118498 0.09720306 0.10464851 0.09751335]]
